{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import data\n",
    "data = pd.read_csv('~/Documents/stock data/data_stocks.csv')\n",
    "# Drop date variable\n",
    "data = data.drop(['DATE'], 1)\n",
    "# Dimensions of dataset\n",
    "n = data.shape[0]\n",
    "p = data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tyler/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(data['SP500'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make data a numpy array\n",
    "data = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2363.6101,   42.33  ,  143.68  , ...,   63.86  ,  122.    ,\n",
       "          53.35  ],\n",
       "       [2364.1001,   42.36  ,  143.7   , ...,   63.74  ,  121.77  ,\n",
       "          53.35  ],\n",
       "       [2362.6799,   42.31  ,  143.6901, ...,   63.75  ,  121.7   ,\n",
       "          53.365 ],\n",
       "       ...,\n",
       "       [2470.03  ,   44.74  ,  164.01  , ...,   76.88  ,  114.31  ,\n",
       "          62.685 ],\n",
       "       [2471.49  ,   44.71  ,  163.88  , ...,   76.83  ,  114.23  ,\n",
       "          62.6301],\n",
       "       [2471.49  ,   44.74  ,  163.98  , ...,   76.81  ,  114.28  ,\n",
       "          62.68  ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2363.6101,   42.33  ,  143.68  , ...,   63.86  ,  122.    ,\n",
       "          53.35  ],\n",
       "       [2364.1001,   42.36  ,  143.7   , ...,   63.74  ,  121.77  ,\n",
       "          53.35  ],\n",
       "       [2362.6799,   42.31  ,  143.6901, ...,   63.75  ,  121.7   ,\n",
       "          53.365 ],\n",
       "       ...,\n",
       "       [2475.05  ,   50.54  ,  158.0143, ...,   76.37  ,  117.8688,\n",
       "          61.535 ],\n",
       "       [2474.8601,   50.52  ,  157.8701, ...,   76.35  ,  117.91  ,\n",
       "          61.52  ],\n",
       "       [2474.6201,   50.52  ,  157.8   , ...,   76.335 ,  117.83  ,\n",
       "          61.54  ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and test data\n",
    "train_start = 0\n",
    "train_end = int(np.floor(0.8*n))\n",
    "test_start = train_end\n",
    "test_end = n\n",
    "data_train = data[np.arange(train_start, train_end), :]\n",
    "data_test = data[np.arange(test_start, test_end), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scale data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data_train)\n",
    "data_train = scaler.transform(data_train)\n",
    "data_test = scaler.transform(data_test)\n",
    "# Build X and y\n",
    "X_train = data_train[:, 1:]\n",
    "y_train = data_train[:, 0]\n",
    "X_test = data_test[:, 1:]\n",
    "y_test = data_test[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define a and b as placeholders\n",
    "a = tf.placeholder(dtype=tf.int8)\n",
    "b = tf.placeholder(dtype=tf.int8)\n",
    "\n",
    "# Define the addition\n",
    "c = tf.add(a, b)\n",
    "\n",
    "# Initialize the graph\n",
    "graph = tf.Session()\n",
    "\n",
    "# Run the graph\n",
    "graph.run(c, feed_dict={a: 5, b: 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model architecture parameters\n",
    "n_stocks = 500\n",
    "n_neurons_1 = 1024\n",
    "n_neurons_2 = 512\n",
    "n_neurons_3 = 256\n",
    "n_neurons_4 = 128\n",
    "n_target = 1\n",
    "\n",
    "# Placeholder\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, n_stocks])\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=[None])\n",
    "\n",
    "# Initializers\n",
    "sigma = 1\n",
    "weight_initializer = tf.variance_scaling_initializer(mode=\"fan_avg\", distribution=\"uniform\", scale=sigma)\n",
    "bias_initializer = tf.zeros_initializer()\n",
    "\n",
    "# Layer 1: Variables for hidden weights and biases\n",
    "W_hidden_1 = tf.Variable(weight_initializer([n_stocks, n_neurons_1]))\n",
    "bias_hidden_1 = tf.Variable(bias_initializer([n_neurons_1]))\n",
    "# Layer 2: Variables for hidden weights and biases\n",
    "W_hidden_2 = tf.Variable(weight_initializer([n_neurons_1, n_neurons_2]))\n",
    "bias_hidden_2 = tf.Variable(bias_initializer([n_neurons_2]))\n",
    "# Layer 3: Variables for hidden weights and biases\n",
    "W_hidden_3 = tf.Variable(weight_initializer([n_neurons_2, n_neurons_3]))\n",
    "bias_hidden_3 = tf.Variable(bias_initializer([n_neurons_3]))\n",
    "# Layer 4: Variables for hidden weights and biases\n",
    "W_hidden_4 = tf.Variable(weight_initializer([n_neurons_3, n_neurons_4]))\n",
    "bias_hidden_4 = tf.Variable(bias_initializer([n_neurons_4]))\n",
    "\n",
    "# Output layer: Variables for output weights and biases\n",
    "W_out = tf.Variable(weight_initializer([n_neurons_4, n_target]))\n",
    "bias_out = tf.Variable(bias_initializer([n_target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hidden layer\n",
    "hidden_1 = tf.nn.relu(tf.add(tf.matmul(X, W_hidden_1), bias_hidden_1))\n",
    "hidden_2 = tf.nn.relu(tf.add(tf.matmul(hidden_1, W_hidden_2), bias_hidden_2))\n",
    "hidden_3 = tf.nn.relu(tf.add(tf.matmul(hidden_2, W_hidden_3), bias_hidden_3))\n",
    "hidden_4 = tf.nn.relu(tf.add(tf.matmul(hidden_3, W_hidden_4), bias_hidden_4))\n",
    "\n",
    "# Output layer (must be transposed)\n",
    "out = tf.transpose(tf.add(tf.matmul(hidden_4, W_out), bias_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cost function\n",
    "mse = tf.reduce_mean(tf.squared_difference(out, Y))\n",
    "\n",
    "# Optimizer\n",
    "opt = tf.train.AdamOptimizer().minimize(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0030936473\n"
     ]
    }
   ],
   "source": [
    "# Make Session\n",
    "net = tf.Session()\n",
    "# Run initializer\n",
    "net.run(tf.global_variables_initializer())\n",
    "\n",
    "# Setup interactive plot\n",
    "plt.ion()\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "line1, = ax1.plot(y_test)\n",
    "line2, = ax1.plot(y_test*0.5)\n",
    "plt.show()\n",
    "\n",
    "# Number of epochs and batch size\n",
    "epochs = 10\n",
    "batch_size = 256\n",
    "\n",
    "for e in range(epochs):\n",
    "\n",
    "    # Shuffle training data\n",
    "    shuffle_indices = np.random.permutation(np.arange(len(y_train)))\n",
    "    X_train = X_train[shuffle_indices]\n",
    "    y_train = y_train[shuffle_indices]\n",
    "\n",
    "    # Minibatch training\n",
    "    for i in range(0, len(y_train) // batch_size):\n",
    "        start = i * batch_size\n",
    "        batch_x = X_train[start:start + batch_size]\n",
    "        batch_y = y_train[start:start + batch_size]\n",
    "        # Run optimizer with batch\n",
    "        net.run(opt, feed_dict={X: batch_x, Y: batch_y})\n",
    "\n",
    "        # Show progress\n",
    "        if np.mod(i, 5) == 0:\n",
    "            # Prediction\n",
    "            pred = net.run(out, feed_dict={X: X_test})\n",
    "            line2.set_ydata(pred)\n",
    "            plt.title('Epoch ' + str(e) + ', Batch ' + str(i))\n",
    "            file_name = 'img/epoch_' + str(e) + '_batch_' + str(i) + '.jpg'\n",
    "            plt.savefig(file_name)\n",
    "            plt.pause(0.01)\n",
    "# Print final MSE after Training\n",
    "mse_final = net.run(mse, feed_dict={X: X_test, Y: y_test})\n",
    "print(mse_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
